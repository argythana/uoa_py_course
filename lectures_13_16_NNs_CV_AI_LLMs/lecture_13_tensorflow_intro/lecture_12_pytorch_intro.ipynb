{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "474d2a19-2309-41fb-871b-2d3c5c092ea4",
   "metadata": {},
   "source": [
    "# Lecture 12. Intro to Deep Learning with pytorch\n",
    "\n",
    "[Pytorch site](https://pytorch.org/)\n",
    "\n",
    "[An actually excellent kaggle tutorial](https://www.kaggle.com/code/alejopaullier/introduction-to-lstm)\n",
    "\n",
    "[Installation instructions:](https://pytorch.org/get-started/locally/) Read carefully.  \n",
    "Choose the right installation for your system.   \n",
    "\n",
    "If you want, make in a different folder, install conda and create a new venv for pytorch using conda or just ```pip install torch```.  \n",
    "I recommend to use a separate folder and install conda to create a different virtual enviroment,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3774269-1b55-4f15-9a1a-dffc39022d7a",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef9437-9123-4e04-bae6-aad1e0dbe0a4",
   "metadata": {},
   "source": [
    "### tensor  \n",
    "### layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d857306-7a4d-46f4-ac90-c19636a1741c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:00:57.090687Z",
     "start_time": "2024-05-31T13:00:55.894337Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "# use this for categorical nominal (not Ordinal )target variables\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7521b81b-bdba-490e-ad24-30c7f6fdd4a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:00:57.394950Z",
     "start_time": "2024-05-31T13:00:57.091633Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the CSV data into a pandas DataFrame\n",
    "df = pd.read_csv('har_train.csv')\n",
    "\n",
    "# Convert the DataFrame into a PyTorch tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6003a2-a9a2-4ac4-95fd-2c5afcf470b0",
   "metadata": {},
   "source": [
    "## EDA\n",
    "[kaggle notebook](https://www.kaggle.com/code/abheeshthmishra/eda-of-human-activity-recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6655fd55-4e7b-4bd8-b39b-b9a7a684a640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:00:57.397303Z",
     "start_time": "2024-05-31T13:00:57.395742Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6034ae1f-8902-4f78-b8f1-4c161fd5f927",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f96ce72e-60a7-40c2-9c8f-b2c821f84468",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:00:57.402543Z",
     "start_time": "2024-05-31T13:00:57.398628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64'), dtype('int64'), dtype('O')], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "598f2320-734f-4de5-8059-7269b4e22c54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:00:57.412962Z",
     "start_time": "2024-05-31T13:00:57.403926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Activity'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Select columns with dtype('O') Object\n",
    "object_columns = df.select_dtypes(include=['O']).columns\n",
    "\n",
    "print(object_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d0009bc-2367-48bd-a7ba-2d25d1e38d1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:00:57.418383Z",
     "start_time": "2024-05-31T13:00:57.413936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "Name: Activity, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target variable to encode\n",
    "target = df['Activity']\n",
    "\n",
    "# Initialize a label encoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the target column\n",
    "df['Activity'] = encoder.fit_transform(target)\n",
    "df.Activity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf2cbe5e-744d-45b6-93f7-44121366676c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:00:57.421338Z",
     "start_time": "2024-05-31T13:00:57.418980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64'), dtype('int64')], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9322a615-07ef-4f97-b462-dfcea8f3d9b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:00:57.459407Z",
     "start_time": "2024-05-31T13:00:57.421881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8858e-01, -2.0294e-02, -1.3291e-01,  ..., -5.8627e-02,\n",
       "          1.0000e+00,  2.0000e+00],\n",
       "        [ 2.7842e-01, -1.6411e-02, -1.2352e-01,  ..., -5.4317e-02,\n",
       "          1.0000e+00,  2.0000e+00],\n",
       "        [ 2.7965e-01, -1.9467e-02, -1.1346e-01,  ..., -4.9118e-02,\n",
       "          1.0000e+00,  2.0000e+00],\n",
       "        ...,\n",
       "        [ 2.7339e-01, -1.7011e-02, -4.5022e-02,  ...,  4.0811e-02,\n",
       "          3.0000e+01,  5.0000e+00],\n",
       "        [ 2.8965e-01, -1.8843e-02, -1.5828e-01,  ...,  2.5339e-02,\n",
       "          3.0000e+01,  5.0000e+00],\n",
       "        [ 3.5150e-01, -1.2423e-02, -2.0387e-01,  ...,  3.6695e-02,\n",
       "          3.0000e+01,  5.0000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor = torch.tensor(df.values.astype(float))  #\n",
    "tensor_hra = torch.tensor(df.values).float()\n",
    "\n",
    "tensor_hra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a17e4b835c4031ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:00:57.462649Z",
     "start_time": "2024-05-31T13:00:57.460033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2.,  ..., 5., 5., 5.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_tensor = tensor_hra[:, :-1]\n",
    "target_tensor = tensor_hra[:, -1]\n",
    "target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ca9270141bb42e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:00:57.465745Z",
     "start_time": "2024-05-31T13:00:57.463723Z"
    }
   },
   "outputs": [],
   "source": [
    "#tensor_hra is your input data and target_tensor is your target data\n",
    "dataset = TensorDataset(features_tensor, target_tensor)\n",
    "\n",
    "inputs = features_tensor\n",
    "# Define your batch size\n",
    "batch_size = inputs.size(0)  \n",
    "# Create a DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e491e5ab3388b58a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:00:57.467458Z",
     "start_time": "2024-05-31T13:00:57.466312Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f3d0638e0ff03b6",
   "metadata": {},
   "source": [
    "NUM_FEATURES: This is the number of features in your data, which corresponds to the second dimension of your data tensor.\n",
    "HIDDEN_SIZE: This is a hyperparameter that you choose. It represents the number of features in the hidden state. In your case, you've chosen 16.\n",
    "NUM_LAYERS: This is also a hyperparameter that you choose. It represents the number of LSTM layers in the LSTM network. In your case, you've chosen 2.\n",
    "NUM_CLASSES: This is the number of unique values in your target variable. You can get this by applying the torch.unique() function to your target tensor and getting its length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f01b09356e4645c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:00:57.469713Z",
     "start_time": "2024-05-31T13:00:57.467923Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_FEATURES = features_tensor.shape[1]  # Number of features in your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4a8025ac8f2a540",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:00:57.472354Z",
     "start_time": "2024-05-31T13:00:57.470570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "562"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd88ad9c3e24e3c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:00:57.473894Z",
     "start_time": "2024-05-31T13:00:57.472820Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d789ae5a30970f34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:00:57.476005Z",
     "start_time": "2024-05-31T13:00:57.474312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4131824"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff4927eb4b7a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Inputs shape: {inputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419c02602a2054fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a ready lstm model for the data\n",
    "# Define the LSTM model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "635602dc2ff90d17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T13:09:51.267272Z",
     "start_time": "2024-05-31T13:09:51.259874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7bc5b32070>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial project configuration\n",
    "result = []\n",
    "project_name = 'Human Activity Recognition'\n",
    "arch = \"Convolution + pooling + convolution + pooling + dense + dense + dense + output\"\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "torch.manual_seed(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21ae96afcba4b733",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:43:32.039323Z",
     "start_time": "2024-05-31T12:43:32.037362Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64  # Define your batch size\n",
    "# SEQUENCE_LENGTH = 50  # Define your sequence length\n",
    "INPUT_SIZE = 562  # Define your input size\n",
    "HIDDEN_SIZE = 16  # Define the number of features in the hidden state\n",
    "NUM_LAYERS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7b5829e032f20b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:43:12.231897Z",
     "start_time": "2024-05-31T12:43:12.228610Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assuming 'dataset' is your Dataset object\n",
    "\n",
    "dataset = TensorDataset(features_tensor, target_tensor)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c851ecc9a26d50f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:43:12.853703Z",
     "start_time": "2024-05-31T12:43:12.848527Z"
    }
   },
   "outputs": [],
   "source": [
    "# === LSTM Network ===\n",
    "LSTM = nn.LSTM(\n",
    "    input_size=INPUT_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,        \n",
    "    num_layers=NUM_LAYERS,       \n",
    "    batch_first=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "186e3a38c1e3962f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:43:13.410669Z",
     "start_time": "2024-05-31T12:43:13.375323Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Pass inputs and initial states through LSTM\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m outputs, (hn, cn) \u001b[38;5;241m=\u001b[39m \u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput batch shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHidden state 0 shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh0\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/venv_projects/uoa_py_course/course_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv_projects/uoa_py_course/course_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venv_projects/uoa_py_course/course_venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:903\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    901\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor unbatched 2-D input, hx and cx should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    902\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malso be 2-D but got (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D) tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 903\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    904\u001b[0m     hx \u001b[38;5;241m=\u001b[39m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    905\u001b[0m \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Now, you can iterate over the DataLoader object to get your inputs\n",
    "for i, (inputs, labels) in enumerate(dataloader):\n",
    "    # Ensure inputs is of the correct shape (BATCH_SIZE, INPUT_SIZE)\n",
    "    inputs = inputs.view(BATCH_SIZE, INPUT_SIZE)\n",
    "\n",
    "    # Initialize hidden and cell states\n",
    "    h0 = torch.randn(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE)\n",
    "    c0 = torch.randn(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE)\n",
    "\n",
    "    # Pass inputs and initial states through LSTM\n",
    "    outputs, (hn, cn) = LSTM(inputs, (h0, c0))\n",
    "\n",
    "    print(f\"Input batch shape: {inputs.shape}\")\n",
    "    print(f\"Hidden state 0 shape: {h0.shape}\")\n",
    "    print(f\"Cell state 0 shape: {c0.shape}\")\n",
    "    print(f\"Output batch shape: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46d6731a9de21fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acc8a355c0b0cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8932bb1beb1076a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f417e60a941b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02afddef1ba78a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94002dc328cd85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb84f793133e45e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8356c82a33e3b2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5651024aa4c7300a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:25:14.347080Z",
     "start_time": "2024-05-31T12:25:14.345412Z"
    }
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 16  # Number of features in the hidden state\n",
    "NUM_LAYERS = 2  # Number of LSTM layers in the LSTM network\n",
    "NUM_CLASSES = len(torch.unique(target_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be905ef927269c8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:25:14.349982Z",
     "start_time": "2024-05-31T12:25:14.347548Z"
    }
   },
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.layer3 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93e48e8d63621062",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:25:14.352597Z",
     "start_time": "2024-05-31T12:25:14.350618Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ClassificationModel(input_size=562, hidden_size=20, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70754ad6f49bf107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:28:29.428093Z",
     "start_time": "2024-05-31T12:28:29.424121Z"
    }
   },
   "outputs": [],
   "source": [
    "# Perform a forward pass\n",
    "outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4dc24ad65344c66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:28:34.055853Z",
     "start_time": "2024-05-31T12:28:34.053063Z"
    }
   },
   "outputs": [],
   "source": [
    "labels=target_tensor.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7160ce5ed99bd2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:26:01.852450Z",
     "start_time": "2024-05-31T12:26:01.846309Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df5038668ce6a80f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:28:35.413141Z",
     "start_time": "2024-05-31T12:28:35.408945Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "labels = labels.long()\n",
    "loss = criterion(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92cf060a8b6a538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:28:35.836453Z",
     "start_time": "2024-05-31T12:28:35.834254Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0916f7f8225c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# === LSTM Network ===\n",
    "LSTM = nn.LSTM(\n",
    "    input_size=INPUT_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,        \n",
    "    num_layers=NUM_LAYERS,       \n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "inputs = torch.randn(BATCH_SIZE,  INPUT_SIZE) # LSTM Network input\n",
    "h0 = torch.randn(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE) # Initial Hidden state\n",
    "c0 = torch.randn(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE) # Initial Cell state\n",
    "outputs, (hn, cn) = LSTM(inputs, (h0, c0)) # LSTM Network output\n",
    "\n",
    "print(f\"Input batch shape: {inputs.shape}\")\n",
    "print(f\"Hidden state 0 shape: {h0.shape}\")\n",
    "print(f\"Cell state 0 shape: {c0.shape}\")\n",
    "print(f\"Output batch shape: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebb20460ce0a56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e796d07ce4761ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c6cdbcf40b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6d0bd3-ef7b-461a-9398-5dcc164f5c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8 # Number of sequences in your batch\n",
    "HIDDEN_SIZE = 16 # Number of features in the hidden state \n",
    "INPUT_SIZE = 563 # Size of each embedding in the sequence\n",
    "NUM_LAYERS = 3 # Number of LSTM layers in the LSTM network\n",
    "SEQUENCE_LENGTH = 50 # Number of embeddings per sequence\n",
    "\n",
    "# === LSTM Network ===\n",
    "LSTM = nn.LSTM(\n",
    "    input_size=INPUT_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,        \n",
    "    num_layers=NUM_LAYERS,       \n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "inputs = tensor_hra\n",
    "# h0 = torch.randn(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE) # Initial Hidden state\n",
    "# c0 = torch.randn(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE) # Initial Cell state\n",
    "outputs= LSTM(inputs) # LSTM Network output\n",
    "\n",
    "print(f\"Input batch shape: {inputs.shape}\")\n",
    "print(f\"Hidden state 0 shape: {h0.shape}\")\n",
    "print(f\"Cell state 0 shape: {c0.shape}\")\n",
    "# print(f\"Output batch shape: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bd4ee9-8eb4-4a7c-9155-90749a79172c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ea593-8c3b-4a95-99f6-85f2b64cf4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003c488b-7224-4a18-b8cf-11ab163c178b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119452c3-fbcb-4cfc-95ae-48463ebcd9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f84702-32cb-4364-abaf-1224138cbbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, tensor_data):\n",
    "        super(Net, self).__init__()\n",
    "        self.tensor_data = tensor_data\n",
    "        self.fc1 = nn.Linear(16, 32)  # 16 input units to 32 output units\n",
    "        self.fc2 = nn.Linear(32, 64)  # 32 input units to 64 output units\n",
    "        self.fc3 = nn.Linear(64, 10)  # 64 input units to 10 output units\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create the network\n",
    "net = Net(tensor_hra)\n",
    "print(net)\n",
    "\n",
    "\n",
    "# Perform a forward pass\n",
    "out = net()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd0485-8534-4cc3-a75c-313f754b05bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(16, 32)  # 16 input units to 32 output units\n",
    "        self.fc2 = nn.Linear(32, 64)  # 32 input units to 64 output units\n",
    "        self.fc3 = nn.Linear(64, 10)  # 64 input units to 10 output units\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create the network\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "# Create a random tensor of size (1, 16)\n",
    "input = torch.randn(1, 16)\n",
    "\n",
    "# Perform a forward pass\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a31a74-fcea-4b36-92ad-b8c1fe81c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the network using nn.Sequential\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(16, 32),  # 16 input units to 32 output units\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 64),  # 32 input units to 64 output units\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10)   # 64 input units to 10 output units\n",
    ")\n",
    "\n",
    "print(net)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Perform a forward pass\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baf993e-e35f-476f-949f-8aef84e63b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8 # Number of sequences in your batch\n",
    "HIDDEN_SIZE = 16 # Number of features in the hidden state \n",
    "INPUT_SIZE = 384 # Size of each embedding in the sequence\n",
    "NUM_LAYERS = 2 # Number of LSTM layers in the LSTM network\n",
    "SEQUENCE_LENGTH = 50 # Number of embeddings per sequence\n",
    "\n",
    "# === LSTM Network ===\n",
    "LSTM = nn.LSTM(\n",
    "    input_size=INPUT_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,        \n",
    "    num_layers=NUM_LAYERS,       \n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "inputs = torch.randn(BATCH_SIZE, SEQUENCE_LENGTH, INPUT_SIZE) # LSTM Network input\n",
    "h0 = torch.randn(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE) # Initial Hidden state\n",
    "c0 = torch.randn(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE) # Initial Cell state\n",
    "outputs, (hn, cn) = LSTM(inputs, (h0, c0)) # LSTM Network output\n",
    "\n",
    "print(f\"Input batch shape: {inputs.shape}\")\n",
    "print(f\"Hidden state 0 shape: {h0.shape}\")\n",
    "print(f\"Cell state 0 shape: {c0.shape}\")\n",
    "print(f\"Output batch shape: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c45865-1015-4d2b-b6f0-432d6d4c4c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c57b35-1069-4904-8dc3-e8bfa2c461b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
