{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97e725d2-4fb3-4fb3-898a-b2cfcd5b072b",
   "metadata": {},
   "source": [
    "# Lecture 12. Intro to Deep Learning with pytorch\n",
    "\n",
    "[Pytorch site](https://pytorch.org/)\n",
    "\n",
    "[An actually excellent kaggle tutorial](https://www.kaggle.com/code/alejopaullier/introduction-to-lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce36a451-9d85-482e-9a75-553bbdc226ef",
   "metadata": {},
   "source": [
    "[Installation instructions:](https://pytorch.org/get-started/locally/) Read carefully.  \n",
    "Choose the right installation for your system.   \n",
    "\n",
    "If you want, make in a different folder, install conda and create a new venv for pytorch using conda or just ```pip install torch```.  \n",
    "I recommend to use a separate folder and install conda to create a different virtual enviroment,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3774269-1b55-4f15-9a1a-dffc39022d7a",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef9437-9123-4e04-bae6-aad1e0dbe0a4",
   "metadata": {},
   "source": [
    "### tensor  \n",
    "### layers"
   ]
  },
  {
   "cell_type": "code",
   "id": "0d857306-7a4d-46f4-ac90-c19636a1741c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:25:13.987776Z",
     "start_time": "2024-05-31T12:25:12.805442Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "# use this for categorical nominal (not Ordinal )target variables\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "7521b81b-bdba-490e-ad24-30c7f6fdd4a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:25:14.276511Z",
     "start_time": "2024-05-31T12:25:13.989409Z"
    }
   },
   "source": [
    "# Load the CSV data into a pandas DataFrame\n",
    "df = pd.read_csv('har_train.csv')\n",
    "\n",
    "# Convert the DataFrame into a PyTorch tensor"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "7f6003a2-a9a2-4ac4-95fd-2c5afcf470b0",
   "metadata": {},
   "source": [
    "## EDA\n",
    "[kaggle notebook](https://www.kaggle.com/code/abheeshthmishra/eda-of-human-activity-recognition)"
   ]
  },
  {
   "cell_type": "code",
   "id": "6655fd55-4e7b-4bd8-b39b-b9a7a684a640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:25:14.279272Z",
     "start_time": "2024-05-31T12:25:14.277487Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "6034ae1f-8902-4f78-b8f1-4c161fd5f927",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "id": "f96ce72e-60a7-40c2-9c8f-b2c821f84468",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:25:14.285703Z",
     "start_time": "2024-05-31T12:25:14.281383Z"
    }
   },
   "source": [
    "df.dtypes.unique()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64'), dtype('int64'), dtype('O')], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "598f2320-734f-4de5-8059-7269b4e22c54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:25:14.289145Z",
     "start_time": "2024-05-31T12:25:14.286395Z"
    }
   },
   "source": [
    "# Select columns with dtype('O') Object\n",
    "object_columns = df.select_dtypes(include=['O']).columns\n",
    "\n",
    "print(object_columns)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Activity'], dtype='object')\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "0d0009bc-2367-48bd-a7ba-2d25d1e38d1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:25:14.294271Z",
     "start_time": "2024-05-31T12:25:14.290079Z"
    }
   },
   "source": [
    "# target variable to encode\n",
    "target = df['Activity']\n",
    "\n",
    "# Initialize a label encoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the target column\n",
    "df['Activity'] = encoder.fit_transform(target)\n",
    "\n",
    "df.Activity.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "Name: Activity, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "bf2cbe5e-744d-45b6-93f7-44121366676c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:25:14.297809Z",
     "start_time": "2024-05-31T12:25:14.295058Z"
    }
   },
   "source": [
    "df.dtypes.unique()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64'), dtype('int64')], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "9322a615-07ef-4f97-b462-dfcea8f3d9b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:25:14.332090Z",
     "start_time": "2024-05-31T12:25:14.298430Z"
    }
   },
   "source": [
    "# tensor = torch.tensor(df.values.astype(float))  #\n",
    "tensor_hra = torch.tensor(df.values).float()\n",
    "\n",
    "\n",
    "tensor_hra\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8858e-01, -2.0294e-02, -1.3291e-01,  ..., -5.8627e-02,\n",
       "          1.0000e+00,  2.0000e+00],\n",
       "        [ 2.7842e-01, -1.6411e-02, -1.2352e-01,  ..., -5.4317e-02,\n",
       "          1.0000e+00,  2.0000e+00],\n",
       "        [ 2.7965e-01, -1.9467e-02, -1.1346e-01,  ..., -4.9118e-02,\n",
       "          1.0000e+00,  2.0000e+00],\n",
       "        ...,\n",
       "        [ 2.7339e-01, -1.7011e-02, -4.5022e-02,  ...,  4.0811e-02,\n",
       "          3.0000e+01,  5.0000e+00],\n",
       "        [ 2.8965e-01, -1.8843e-02, -1.5828e-01,  ...,  2.5339e-02,\n",
       "          3.0000e+01,  5.0000e+00],\n",
       "        [ 3.5150e-01, -1.2423e-02, -2.0387e-01,  ...,  3.6695e-02,\n",
       "          3.0000e+01,  5.0000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:25:14.335535Z",
     "start_time": "2024-05-31T12:25:14.332700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features_tensor = tensor_hra[:, :-1]\n",
    "target_tensor = tensor_hra[:, -1]\n",
    "target_tensor"
   ],
   "id": "a17e4b835c4031ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2.,  ..., 5., 5., 5.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:25:14.338851Z",
     "start_time": "2024-05-31T12:25:14.336862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#tensor_hra is your input data and target_tensor is your target data\n",
    "dataset = TensorDataset(features_tensor, target_tensor)\n",
    "\n",
    "inputs = features_tensor\n",
    "# Define your batch size\n",
    "batch_size = inputs.size(0)  \n",
    "# Create a DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ],
   "id": "1ca9270141bb42e1",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:25:14.340645Z",
     "start_time": "2024-05-31T12:25:14.339505Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e491e5ab3388b58a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "NUM_FEATURES: This is the number of features in your data, which corresponds to the second dimension of your data tensor.\n",
    "HIDDEN_SIZE: This is a hyperparameter that you choose. It represents the number of features in the hidden state. In your case, you've chosen 16.\n",
    "NUM_LAYERS: This is also a hyperparameter that you choose. It represents the number of LSTM layers in the LSTM network. In your case, you've chosen 2.\n",
    "NUM_CLASSES: This is the number of unique values in your target variable. You can get this by applying the torch.unique() function to your target tensor and getting its length."
   ],
   "id": "5f3d0638e0ff03b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:25:14.342503Z",
     "start_time": "2024-05-31T12:25:14.341096Z"
    }
   },
   "cell_type": "code",
   "source": "NUM_FEATURES = features_tensor.shape[1]  # Number of features in your data",
   "id": "f01b09356e4645c8",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:25:14.344860Z",
     "start_time": "2024-05-31T12:25:14.343038Z"
    }
   },
   "cell_type": "code",
   "source": "NUM_FEATURES",
   "id": "c4a8025ac8f2a540",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "562"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bd88ad9c3e24e3c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d789ae5a30970f34"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8cd32d827fde9f69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:39:05.713527Z",
     "start_time": "2024-05-31T12:39:05.708342Z"
    }
   },
   "cell_type": "code",
   "source": "inputs.numel() ",
   "id": "b6aafb23b5a8aa38",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35968"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:39:15.758886Z",
     "start_time": "2024-05-31T12:39:15.754699Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Inputs shape: {inputs.shape}\")",
   "id": "48bbbf14316bf297",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: torch.Size([64, 562])\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:43:32.039323Z",
     "start_time": "2024-05-31T12:43:32.037362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 64  # Define your batch size\n",
    "# SEQUENCE_LENGTH = 50  # Define your sequence length\n",
    "INPUT_SIZE = 562  # Define your input size\n",
    "HIDDEN_SIZE = 16  # Define the number of features in the hidden state\n",
    "NUM_LAYERS = 10"
   ],
   "id": "21ae96afcba4b733",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:43:12.231897Z",
     "start_time": "2024-05-31T12:43:12.228610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming 'dataset' is your Dataset object\n",
    "\n",
    "dataset = TensorDataset(features_tensor, target_tensor)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ],
   "id": "a7b5829e032f20b9",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:43:12.853703Z",
     "start_time": "2024-05-31T12:43:12.848527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === LSTM Network ===\n",
    "LSTM = nn.LSTM(\n",
    "    input_size=INPUT_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,        \n",
    "    num_layers=NUM_LAYERS,       \n",
    "    batch_first=True\n",
    ")\n"
   ],
   "id": "4c851ecc9a26d50f",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:43:13.410669Z",
     "start_time": "2024-05-31T12:43:13.375323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Now, you can iterate over the DataLoader object to get your inputs\n",
    "for i, (inputs, labels) in enumerate(dataloader):\n",
    "    # Ensure inputs is of the correct shape (BATCH_SIZE, INPUT_SIZE)\n",
    "    inputs = inputs.view(BATCH_SIZE, INPUT_SIZE)\n",
    "\n",
    "    # Initialize hidden and cell states\n",
    "    h0 = torch.randn(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE)\n",
    "    c0 = torch.randn(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE)\n",
    "\n",
    "    # Pass inputs and initial states through LSTM\n",
    "    outputs, (hn, cn) = LSTM(inputs, (h0, c0))\n",
    "\n",
    "    print(f\"Input batch shape: {inputs.shape}\")\n",
    "    print(f\"Hidden state 0 shape: {h0.shape}\")\n",
    "    print(f\"Cell state 0 shape: {c0.shape}\")\n",
    "    print(f\"Output batch shape: {outputs.shape}\")"
   ],
   "id": "186e3a38c1e3962f",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[47], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m c0 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrandn(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Pass inputs and initial states through LSTM\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m outputs, (hn, cn) \u001B[38;5;241m=\u001B[39m \u001B[43mLSTM\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mh0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc0\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput batch shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minputs\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHidden state 0 shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mh0\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/venv_projects/uoa_py_course/course_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv_projects/uoa_py_course/course_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/venv_projects/uoa_py_course/course_venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:903\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[0;34m(self, input, hx)\u001B[0m\n\u001B[1;32m    900\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m hx[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m hx[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m    901\u001B[0m         msg \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFor unbatched 2-D input, hx and cx should \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    902\u001B[0m                \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124malso be 2-D but got (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhx[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdim()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m-D, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhx[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mdim()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m-D) tensors\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 903\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg)\n\u001B[1;32m    904\u001B[0m     hx \u001B[38;5;241m=\u001B[39m (hx[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m), hx[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m    905\u001B[0m \u001B[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001B[39;00m\n\u001B[1;32m    906\u001B[0m \u001B[38;5;66;03m# the user believes he/she is passing in.\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f46d6731a9de21fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6acc8a355c0b0cbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8932bb1beb1076a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d30f417e60a941b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e02afddef1ba78a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f94002dc328cd85f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "eb84f793133e45e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8356c82a33e3b2b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:25:14.347080Z",
     "start_time": "2024-05-31T12:25:14.345412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "HIDDEN_SIZE = 16  # Number of features in the hidden state\n",
    "NUM_LAYERS = 2  # Number of LSTM layers in the LSTM network\n",
    "NUM_CLASSES = len(torch.unique(target_tensor))"
   ],
   "id": "5651024aa4c7300a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:25:14.349982Z",
     "start_time": "2024-05-31T12:25:14.347548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.layer3 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ],
   "id": "be905ef927269c8f",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:25:14.352597Z",
     "start_time": "2024-05-31T12:25:14.350618Z"
    }
   },
   "cell_type": "code",
   "source": "model = ClassificationModel(input_size=562, hidden_size=20, num_classes=NUM_CLASSES)",
   "id": "93e48e8d63621062",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:28:29.428093Z",
     "start_time": "2024-05-31T12:28:29.424121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Perform a forward pass\n",
    "outputs = model(inputs)"
   ],
   "id": "70754ad6f49bf107",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:28:34.055853Z",
     "start_time": "2024-05-31T12:28:34.053063Z"
    }
   },
   "cell_type": "code",
   "source": "labels=target_tensor.long()",
   "id": "b4dc24ad65344c66",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:26:01.852450Z",
     "start_time": "2024-05-31T12:26:01.846309Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d7160ce5ed99bd2a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:28:35.413141Z",
     "start_time": "2024-05-31T12:28:35.408945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "labels = labels.long()\n",
    "loss = criterion(outputs, labels)"
   ],
   "id": "df5038668ce6a80f",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T12:28:35.836453Z",
     "start_time": "2024-05-31T12:28:35.834254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs\n",
    "epochs = 5"
   ],
   "id": "92cf060a8b6a538",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# === LSTM Network ===\n",
    "LSTM = nn.LSTM(\n",
    "    input_size=INPUT_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,        \n",
    "    num_layers=NUM_LAYERS,       \n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "inputs = torch.randn(BATCH_SIZE,  INPUT_SIZE) # LSTM Network input\n",
    "h0 = torch.randn(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE) # Initial Hidden state\n",
    "c0 = torch.randn(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE) # Initial Cell state\n",
    "outputs, (hn, cn) = LSTM(inputs, (h0, c0)) # LSTM Network output\n",
    "\n",
    "print(f\"Input batch shape: {inputs.shape}\")\n",
    "print(f\"Hidden state 0 shape: {h0.shape}\")\n",
    "print(f\"Cell state 0 shape: {c0.shape}\")\n",
    "print(f\"Output batch shape: {outputs.shape}\")"
   ],
   "id": "4b0916f7f8225c60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "eebb20460ce0a56d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4e796d07ce4761ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "551c6cdbcf40b50",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8e6d0bd3-ef7b-461a-9398-5dcc164f5c05",
   "metadata": {},
   "source": [
    "BATCH_SIZE = 8 # Number of sequences in your batch\n",
    "HIDDEN_SIZE = 16 # Number of features in the hidden state \n",
    "INPUT_SIZE = 563 # Size of each embedding in the sequence\n",
    "NUM_LAYERS = 3 # Number of LSTM layers in the LSTM network\n",
    "SEQUENCE_LENGTH = 50 # Number of embeddings per sequence\n",
    "\n",
    "# === LSTM Network ===\n",
    "LSTM = nn.LSTM(\n",
    "    input_size=INPUT_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,        \n",
    "    num_layers=NUM_LAYERS,       \n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "inputs = tensor_hra\n",
    "# h0 = torch.randn(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE) # Initial Hidden state\n",
    "# c0 = torch.randn(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE) # Initial Cell state\n",
    "outputs= LSTM(inputs) # LSTM Network output\n",
    "\n",
    "print(f\"Input batch shape: {inputs.shape}\")\n",
    "print(f\"Hidden state 0 shape: {h0.shape}\")\n",
    "print(f\"Cell state 0 shape: {c0.shape}\")\n",
    "# print(f\"Output batch shape: {outputs.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "07bd4ee9-8eb4-4a7c-9155-90749a79172c",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "594ea593-8c3b-4a95-99f6-85f2b64cf4e2",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "003c488b-7224-4a18-b8cf-11ab163c178b",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "119452c3-fbcb-4cfc-95ae-48463ebcd9b1",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e1f84702-32cb-4364-abaf-1224138cbbe8",
   "metadata": {},
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, tensor_data):\n",
    "        super(Net, self).__init__()\n",
    "        self.tensor_data = tensor_data\n",
    "        self.fc1 = nn.Linear(16, 32)  # 16 input units to 32 output units\n",
    "        self.fc2 = nn.Linear(32, 64)  # 32 input units to 64 output units\n",
    "        self.fc3 = nn.Linear(64, 10)  # 64 input units to 10 output units\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create the network\n",
    "net = Net(tensor_hra)\n",
    "print(net)\n",
    "\n",
    "\n",
    "# Perform a forward pass\n",
    "out = net()\n",
    "print(out)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4cbd0485-8534-4cc3-a75c-313f754b05bb",
   "metadata": {},
   "source": [
    "# Define the network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(16, 32)  # 16 input units to 32 output units\n",
    "        self.fc2 = nn.Linear(32, 64)  # 32 input units to 64 output units\n",
    "        self.fc3 = nn.Linear(64, 10)  # 64 input units to 10 output units\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create the network\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "# Create a random tensor of size (1, 16)\n",
    "input = torch.randn(1, 16)\n",
    "\n",
    "# Perform a forward pass\n",
    "out = net(input)\n",
    "print(out)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e1a31a74-fcea-4b36-92ad-b8c1fe81c121",
   "metadata": {},
   "source": [
    "\n",
    "# Define the network using nn.Sequential\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(16, 32),  # 16 input units to 32 output units\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 64),  # 32 input units to 64 output units\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10)   # 64 input units to 10 output units\n",
    ")\n",
    "\n",
    "print(net)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Perform a forward pass\n",
    "out = net(input)\n",
    "print(out)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2baf993e-e35f-476f-949f-8aef84e63b51",
   "metadata": {},
   "source": [
    "BATCH_SIZE = 8 # Number of sequences in your batch\n",
    "HIDDEN_SIZE = 16 # Number of features in the hidden state \n",
    "INPUT_SIZE = 384 # Size of each embedding in the sequence\n",
    "NUM_LAYERS = 2 # Number of LSTM layers in the LSTM network\n",
    "SEQUENCE_LENGTH = 50 # Number of embeddings per sequence\n",
    "\n",
    "# === LSTM Network ===\n",
    "LSTM = nn.LSTM(\n",
    "    input_size=INPUT_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,        \n",
    "    num_layers=NUM_LAYERS,       \n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "inputs = torch.randn(BATCH_SIZE, SEQUENCE_LENGTH, INPUT_SIZE) # LSTM Network input\n",
    "h0 = torch.randn(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE) # Initial Hidden state\n",
    "c0 = torch.randn(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE) # Initial Cell state\n",
    "outputs, (hn, cn) = LSTM(inputs, (h0, c0)) # LSTM Network output\n",
    "\n",
    "print(f\"Input batch shape: {inputs.shape}\")\n",
    "print(f\"Hidden state 0 shape: {h0.shape}\")\n",
    "print(f\"Cell state 0 shape: {c0.shape}\")\n",
    "print(f\"Output batch shape: {outputs.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62c45865-1015-4d2b-b6f0-432d6d4c4c33",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "73c57b35-1069-4904-8dc3-e8bfa2c461b4",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
